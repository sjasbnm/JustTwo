{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "class NeuralNet(object): \n",
    "    RNG = np.random.default_rng() \n",
    "    def __init__(self, topology:list[int] = []): \n",
    "        self.topology = topology \n",
    "        self.weight_mats = []         self._init_matrices() \n",
    "    def _init_matrices(self):         #-- set up matrices \n",
    "        if len(self.topology) > 1: \n",
    "            j = 1 \n",
    "            for i in range(len(self.topology)-1): \n",
    "                num_rows = self.topology[i] \n",
    "                num_cols = self.topology[j]                 mat = self.RNG.random(size=(num_rows, num_cols))\n",
    "                self.weight_mats.append(mat) j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(object): \n",
    "    ... \n",
    "    def feedforward(self, input_vector): \n",
    "        I = input_vector         for idx, W in enumerate(self.weight_mats): \n",
    "            I = np.dot(I, W) \n",
    "    \n",
    "            if idx == len(self.weight_mats) - 1: \n",
    "                out_vector = np.tanh(I) #output layer \n",
    "            else: \n",
    "                I = np.tanh(I) #hidden layers         return out_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example dataset (replace with your own)\n",
    "# X is the feature matrix, y is the target\n",
    "# X, y = load_your_data() \n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the MLPClassifier\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),  # Two hidden layers with 100 and 50 neurons\n",
    "    activation='relu',            # Activation function for the hidden layers\n",
    "    solver='adam',                # Optimizer\n",
    "    alpha=0.0001,                 # L2 regularization parameter\n",
    "    max_iter=500,                 # Maximum number of iterations\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
